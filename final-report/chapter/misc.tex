\chapter{Graph 3-coloring games}

In the last chapter, we set the polynomial-hierarchy stage, focusing on circuit
games \(\CircSat‚Çñ\) as canonical examples of \SigmaP k-complete problems.  In
this chapter, we expand that landscape by exploring another collection \SigmaP
k-complete games, played via colorings on graph vertices.

It is only due to the time constraints on this thesis that we stop at one game:
ultimately, I hope to convey, through the examples presented in this chapter,
the sense that there are many, many \SigmaP k-complete games out there, all of
which intuitively stem from classic, well-known \NP-complete puzzles.

%\section{Graph coloring games}

\section{Preliminaries: graphs and proper colorings}

First, we introduce some preliminary definitions about graphs and colorings.  A
graph is a network of \emph{vertices} connected by \emph{edges}.  Formally:

\begin{definition}{(undirected) graphs}{}

  A \Term{graph} \(Œì\) is a pair \((\Vertices(Œì),\Edges(Œì))\) consisting of:
  \begin{itemize}[nosep]
    \item a finite set of \Term{vertices} \(\Vertices(Œì)\), and
    \item a finite set of \Term{edges} \(\Edges(Œì)‚äÜ\Vertices(Œì)√ó\Vertices(Œì)\),
      which represent connections between pairs of vertices.
  \end{itemize}

  For our purposes, edges have no directionality.  That is, when specifying an
  edge, the ordering of vertices doesn't matter: \((u,v)\) specifies the same
  edge as \((v,u)\).

  We say that two vertices \(u,v‚àà\Vertices(Œì)\) are \Term{neighbors}, or that
  they neighbor each other, if \((u,v)‚àà\Edges(Œì)\).

\end{definition}

% TODO example giraph (fun)

The graph coloring games we explore in this thesis are about assigning colors
to vertices on a graph.  We call such an assignment a \emph{vertex coloring}.
Specifically, for sake of simplicity, we restrict our attention to colorings
that involve only three colors.  The main rule constraining these color
assignments is that neighboring vertices must always be colored distinctly---we
call this the \emph{properness} condition.  These terms are defined precisely
below.

\begin{definition}{vertex 3-colorings, properness}{}%

  Let \(Œì\) be a graph. A \Term{vertex 3-coloring} of \(Œì\) is a map
  \(Œ∫\colon\Vertices(Œì)‚Üí\Colors\), which assigns to each vertex one of three
  colors.  In this thesis, we generally just say ``coloring'' to refer to
  ``vertex 3-colorings'', except when specified otherwise.

  A vertex coloring \(Œ∫\) is a \Term{proper} coloring if, for every edge
  \((u,v)‚àà\Edges(Œì)\), \(Œ∫(u)‚â†Œ∫(v)\)---i.e., no neighboring vertices share the
  same color.  To simplify discourse, we also call a particular
  edge/neighboring-pair \((u,v)‚àà\Edges(Œì)\) is \Term{proper} if \(Œ∫(u)‚â†Œ∫(v)\).
  Thus a proper coloring is one where all edges are proper; an improper
  coloring contains at least one improper edge.

\end{definition}

Having established the basic terminology, we now introduce the graph
(3-)coloring games.

\section{The \(0\)-turn game}

The goal of graph coloring games is to assign colors to all vertices so that
the resulting coloring is proper.  To this end, the \(0\)-turn
winning-condition problem is that of checking properness of colorings, called
the \Problem{3-Coloring Properness} problem, or \ColProp{} for short:

\begin{problem}{\Problem{3-Coloring Properness} / \ColProp}{}

  \begin{description}[nosep]
  \item[Given:] a graph and a 3-coloring \(Œ∫\) of the graph (specified by
    listing out each vertex with its color)
  \item[Determine whether:] \(Œ∫\) is a proper coloring
  \end{description}

  %\tcblower
  %\ColProp=\SetBuilder{(\text{graph \(Œì\)},\text{coloring \(Œ∫\)})}{
  %  ‚àÄ(u,v)‚àà\Edges(Œì)\Q Œ∫(u)‚â†Œ∫(v)
  %}
\end{problem}

In order for \ColProp{} to be usable as a basis for polynomial-hierarchy games,
we must first ensure that it itself is in \P.  Indeed, it is:

\begin{theorem}{\(\ColProp‚àà\P\)}{3colprop-in-p}

  \(\ColProp\) is solvable in polynomial time.

\end{theorem}

\begin{proof}

  We describe below a straightforward polynomial-time algorithm computing
  \ColProp.  It iterates through the edges and simply verifies the properness
  condition on each pair of neighbors:

  \begin{algorithm}{a polynomial-time \ColProp{} solver}{}
    \begin{algorithmic}
      \Given{a graph \(Œì\) and a coloring \(Œ∫\colon\Vertices(Œì)‚Üí\Colors\)}%
      \ForEach{\((u,v)‚àà\Edges(Œì)\)}%
      \If{\(Œ∫(u)=Œ∫(v)\)}%
      \LComment{\((u,v)\) is improper!}
      \State{\Return no}%
      \EndIf%
      \EndFor%
      \LComment{all edges have been checked, and no improper ones were found,
      so the coloring is proper}
      \State{\Return yes}%
    \end{algorithmic}
  \end{algorithm}

  The number of edges is, by definition, bounded by the size of the graph, so
  the number of ``for each'' iterations is polynomial. Within each iteration,
  the \(Œ∫(u)=Œ∫(v)\) check runs within polynomial time, so the overall algorithm
  runs in polynomial time as well.  \qedhere

\end{proof}

\section{The \(ùëò\)-turn games}



A graph coloring game is played on an initially uncolored graph \(Œì\).  In a
\(k\)-turn game, the graph's vertices are partitioned into \(k\) groups,
\(V‚ÇÅ,V‚ÇÇ,\dotsc,V‚Çñ\), and players alternate turns assigning colors to the
vertices in each group.  If, on any turn, a player introduces an improper edge
in the (partial) coloring, the other player wins.  If, after all turns, no
improper edges have been introduced---that is, the resulting coloring is
proper---then the \emph{last} player wins.

To help formalize this game, we define exactly what we mean by \emph{partial
coloring}.

\begin{definition}{partial (vertex 3-)colorings}{}

  Let \(Œì\) be a graph.  A \Term{partial (vertex 3-)coloring} is a map
  \(Œ∫\colon\Vertices(Œì)‚Üí\ColorsOpt\), which \emph{optionally} assigns a color to
  each vertex in \(Œì\) (\None{} means no color is assigned).  Where necessary,
  we refer to fully-completed colorings as \Term{total colorings} to
  differentiate them from partial colorings.

  A partial coloring \(Œ∫\) is \Term{proper} if, among the vertices it
  \emph{does} assign a color, there are no improper edges.  That is, for all
  \((u,v)‚àà\Edges(Œì)\), if both \(Œ∫(u)\) and \(Œ∫(v)\) are not \None, then
  \(Œ∫(u)‚â†Œ∫(v)\).

\end{definition}

At the start of the game, no vertices are colored yet---the partial coloring
assigns \None{} to every vertex.  When a player makes a move, they
\emph{augment} the partial coloring with new assignments:

\begin{definition}{augmented coloring}{}

  Let \(Œì\) be a graph, and \(Œ∫\) be a partial coloring on \(Œì\).

  Let \(U‚äÜ\Vertices(Œì)\) be a subset of the vertices such that, for each
  \(u‚ààU\), \(Œ∫(u)=\None\) (all vertices in \(U\) are uncolored), and let
  \(Œ¥\colon U‚Üí\Colors\) be an assignment of colors to every vertex in \(U\).
  Then the \Term{augmented coloring \(Œ∫[Œ¥]\colon\Vertices(Œì)‚Üí\ColorsOpt\)} is
  another partial coloring formed by the combining the two color assignments:
  \[
    Œ∫[Œ¥](v) =
    \begin{cases}
      Œ¥(v) & v‚ààU \\
      Œ∫(v) & v‚àâU
    \end{cases}.
  \]

\end{definition}

Now, we are ready to give the full inductive formulation of \(k\)-turn graph
coloring games.
\begin{itemize}

  \item The \(0\)-turn winning condition is \ColProp: given a totally-colored
    graph, decide whether the coloring is proper.

  \item \(k\)-turn games begin on a partially-colored graph \((Œì,Œ∫)\), where the
    partial coloring \(Œ∫\) comprises color assignments made in previous turns.
    (We discuss in \cref{sec:precolor} TODO restrictions of these games that
    start with completely uncolored graphs.)

    If \(Œ∫\) is improper to begin with, then we posit that the first player
    automatically wins, since that means that the opposite player must have made
    an improper move on their previous turn. Otherwise, the first player colors
    \(U‚ÇÅ\) with a coloring \(Œ¥\), and wins if and only if the remaining
    \((k-1)\)-turn game \(\Paren*{Œì,Œ∫[Œ¥],(U‚ÇÇ,\dotsc,U‚Çñ)}\) is now un-winnable by
    the opposite player.
\end{itemize}


%In \cref{sec:pre-coloring}, we discuss how to
%restrict this formulation to games that start on empty graphs.

%Thus we start with a graph \(Œì\) and a partial coloring \(Œ∫\) of \(Œì\).  The
%\emph{uncolored} vertices in \(Œì\) are partitioned into \(k\) groups,
%\(U‚ÇÅ,U‚ÇÇ,\dotsc,U‚Çñ\).  For each turn \(i\) in \(1,2,\dotsc,k\), player
%\((i\bmod2)\) assigns colors to all vertices in \(U·µ¢\).  If, when doing so, they
%introduce an improper edge, they lose; otherwise, the game proceeds.  If all
%turns finish, and the resulting total coloring is proper, the last player wins.

%\begin{enumerate}
%  \item On the first turn, the first player assigns a coloring \(Œ¥‚ÇÅ\) to \(U‚ÇÅ\),
%    producing a new partial coloring \(Œ∫'=Œ∫[Œ¥‚ÇÅ]\).  If \(Œ∫'\) is improper, then
%    the first player automatically loses; otherwise, the game continues.
%  \item[{[\(2\)--\(k\)]}] The remaining \(k-1\) turns proceed inductively,
%    starting with the new partial coloring \(Œ∫'\), with the first move made by
%    the second player.
%\end{enumerate}
%At the end of all turns, if the resulting coloring is improper, the player who
%introduced the improper edge loses; otherwise, the last player wins.  The
%decision problem: does the first player have a winning strategy?

\begin{problem}{\Problem{3-Colorability} with \(k\) turns / \Col[k]}{}

  \begin{description}[nosep]
    \item[Given:] a partially-colored graph together with a partitioning of its
      vertices, \((Œì,Œ∫,(U‚ÇÅ,U‚ÇÇ,\dotsc,U‚Çñ))\)
    \item[Determine whether:] \(Œ∫\) is improper, or there exists some \(Œ¥\colon
      U‚ÇÅ‚Üí\Colors\) such that
      \begin{nest}
        \(\Paren*{Œì,Œ∫[Œ¥],(U‚ÇÇ,\dotsc,U‚Çñ)}‚àà\Paren*{\Col[k-1]}\Complement\)
      \end{nest}
    \end{description}

\end{problem}

\section{\texorpdfstring{\(\Problem{3Col}‚Çñ‚àà\SigmaP k\)}{\(\Problem{3Col}‚Çñ‚ààùö∫‚Çñùêè\)}, right?}

Having defined \(\Col[k]\) as a \(k\)-turn game problem, we naturally expect
that \(\Col[k]‚àà\SigmaP k\) (the class of all (``reasonable'') \(k\)-turn game
problems).  Indeed, we claim it is, but it isn't immediately obvious \emph{how}.
Specifically, membership in \(\Col[k]\) is conditioned on an extra ``\(Œ∫\) is
improper or'' clause that isn't present in the definition of \SigmaP k problems
(\cref{def:ph}):
\[
  \begin{array}{r@{\;=\;\Big\{\,}c@{\;\Big\vert\;}c@{\quad‚àÉ}r@{\Q}c@{\:‚àà\:}c@{\,\Big\},}}
    \Col[k] & (Œì,Œ∫,\dotsc) & \underline{\text{\(Œ∫\) is improper, or}} & Œ¥ &
    (Œì,Œ∫[Œ¥],\dotsc) & \Paren*{\Col[k-1]}\Complement \\[.5em]
    \Ub[‚àà\SigmaP k]{Œ†} & B && M & (B,M) & \Ub[‚àà\PiP{k-1}]{Œ†'}
  \end{array}
\]

By splitting up the two conditions, we can think of \Col[k] \emph{union} of two
problems:
\[
  \Col[k] = \SetBuilder{(Œì,Œ∫,\dotsc)}{\text{\(Œ∫\) is improper}}
  ‚à™ \SetBuilder*{(Œì,Œ∫,\dotsc)}{‚àÉŒ¥\Q(Œì,Œ∫[Œ¥],\dotsc)‚àà\Col[k-1]}
\]
The first term in the union, determining improperness of \(Œ∫\), is basically
equivalent to \(\ColProp\Complement\), which is in \P{} (\cref{th:3colprop-in-p}
and \cref{cor:p-cop}).  Meanwhile, the second term appears to comply with the
\SigmaP k definition---if we assume (yet unproven, but sort of as an inductive
hypothesis) that \(\Col[k-1]‚àà\SigmaP{k-1}\), then the second term is indeed in
\(\SigmaP k\).

So \Col[k] is the union of a problem in \P{} with a problem \emph{allegedly} in
\SigmaP k.

Then, it makes sense to expect \(\Col[k]‚àà\SigmaP k\) for the
following (conjectured) reasons:
\begin{itemize}
  \item We expect \(\P‚äÜ\SigmaP k\): intuitively, \(0\)-turn games must be easier
    than (at least as easy as) \(k\)-turn games.
  \item The union of two problems in \SigmaP k should also be in \SigmaP k
    (i.e., \SigmaP k is \emph{closed} under union): intuitively, directly
    combining two problems doesn't make them harder.
\end{itemize}
Below, we state these conjectures in general terms and prove them.

\begin{theorem}{games with fewer turns are ``easier''}{fewer-easier}

  For every \(k=0,1,2,\dotsc\),
  \[
    \SigmaP k‚äÜ\SigmaP{k+1}, \qquad
    \SigmaP k‚äÜ\PiP{k+1}, \qquad
    \PiP k‚äÜ\SigmaP{k+1}, \qquad
    \PiP k‚äÜ\PiP{k+1}.
  \]

\end{theorem}

\begin{proof}

  We prove each of the four inclusions separately.
  \begin{enumerate}
    \item \label{it:fewer.ps} Claim: \(\PiP k‚äÜ\SigmaP{k+1}\).

      This follows directly from the definition of \(\SigmaP{k+1}\).  Let
      \(Œ†‚àà\PiP k\), and define
      \[
        Œ†'=\SetBuilder{(X,\text{\color{gray}(empty)})}{X‚ààŒ†}, \qquad p(n)=0.
      \]
      Note that \(Œ†'\) is the same problem as \(Œ†\), differing only in
      ``formatting'' of inputs, so \(Œ†'‚àà\PiP k\) as well.  Thus \(Œ†\) fits the
      definition of a \(\SigmaP{k+1}\) game:
      \begin{nest}
        For all inputs \(X‚àà\Strings\), \(X‚ààŒ†\) if and only if
        \begin{nest}
          letting \(Y\) be the empty string, we have \(\Abs Y=0‚â§p(\Abs X)\), and
          \begin{nest}
            \((X,Y)=(X,\text{\color{gray}(empty)})‚ààŒ†'\).
          \end{nest}
        \end{nest}
      \end{nest}
      Thus \(Œ†‚àà\SigmaP{k+1}\).

      \begin{aside}
        The intuition here: \(Œ†‚àà\PiP k\) is an impossible-to-win \(k\)-turn
        game.  Then, \(Œ†'\) is a \((k+1)\)-turn game in which, on the first
        turn, the other player does \emph{nothing}. Still, they guarantee a win,
        because the remaining game already dooms the second player to a loss.
      \end{aside}

    \item Claim: \(\SigmaP k‚äÜ\PiP{k+1}\).

      This follows directly from the previous result \ref{it:fewer.ps}, since
      \(\SigmaP k=\co\PiP k\) and \(\PiP{k+1}=\co\SigmaP{k+1}\).

    \item \label{it:fewer.ss} Claim: \(\SigmaP k‚äÜ\SigmaP{k+1}\).

      We prove this by induction on \(k\).
      \begin{itemize}
        \item For \(k=0\), \(\SigmaP0=\P=\PiP0\) by definition.  Thus the
          argument from part \ref{it:fewer.ps} applies in this case:
          \(\SigmaP0=\PiP0‚äÜ\SigmaP1\).
        \item For \(k‚â•1\), assume \(\SigmaP{k-1}‚äÜ\SigmaP k\). Suppose
          \(Œ†‚àà\SigmaP k\).  Then there exists a \(Œ†'‚àà\PiP{k-1}\) and a
          polynomial \(p\) such that
          \[
            Œ†=\SetBuilder{X}{‚àÉY\Q \Abs Y‚â§p(\Abs X), \quad (X,Y)‚ààŒ†'}.
          \]
          Recalling that \(\mathbf{Œ†}\) is just \(\co\mathbf{Œ£}\), the induction
          hypothesis implies \(\PiP{k-1}‚äÜ\PiP k\).  Thus \(Œ†'‚àà\PiP{k-1}\) is
          also in \(\PiP k\).  Consequently, \(Œ†\) is also in \(\SigmaP{k+1}\).
          Since \(Œ†\) was arbitrary, we conclude \(\SigmaP k‚äÜ\SigmaP{k+1}\).
      \end{itemize}

    \item Claim: \(\PiP k‚äÜ\PiP{k+1}\).

      This follows directly from the previous result \ref{it:fewer.ss}, since
      \(\mathbf{Œ†}=\co\mathbf{Œ£}\).  \qedhere

  \end{enumerate}

\end{proof}

As a side note, \ref{th:fewer-easier} provides justification for calling the
collection of complexity classes \SigmaP k/\PiP k a \emph{hierarchy}---each
level of the hierarchy is contained within the next, etc.  The following diagram
illustrates this hierarchy of containments:

\begin{center}
  \begin{tikzpicture}

    \tikzset{
      subset/.style={->},
    }

    \matrix[row sep=1em, column sep=4em, matrix of math nodes, nodes={
      draw, draw opacity=1/2, rounded corners=1em/4,
    }]{
      & |(s1)|\SigmaP1=\NP & |(s2)|\SigmaP2 & |(s3)|\SigmaP3 & |(s)[draw=none]|\cdots \\
      |(0)|\SigmaP0=\PiP0=\P & \\
      & |(p1)|\PiP1=\co\NP & |(p2)|\PiP2 & |(p3)|\PiP3 & |(p)[draw=none]|\cdots \\
    };

    \draw[subset] (0) to["\(‚äÜ\)" {above, sloped}] (s1);
    \draw[subset] (0) to["\(‚äÜ\)" {below, sloped}] (p1);

    \foreach \i in {p,s} {
      \foreach \j in {p,s} {
        \draw[subset] (\i1) to (\j2);
        \draw[subset] (\i2) to (\j3);
        \draw[subset] (\i3) to (\j);
      }
    }

  \end{tikzpicture}
\end{center}

%
%\begin{proof}
%
%  %Let \(Œ†‚àà\SigmaP k\); we wish to show that \(Œ†‚àà\SigmaP{k+1}\).
%
%  %Define the problem
%  %\[
%  %  Œ†'=\SetBuilder{(X,œµ)}{X‚ààŒ†},
%  %\]
%  %where \(œµ\) denotes the empty string.  First, note that \(Œ†'\) is trivially
%  %equivalent to \(Œ†\), differing only in the ``formatting'' of instances.  Thus
%  %\(Œ†'‚àà\SigmaP k\) as well.  Next, observe that \(Œ†'\) is polynomially balanced,
%  %since the second element \(œµ\) always has length \(0\).
%
%  %Then we see that \(Œ†\) fits the definition of a \SigmaP{k+1} problem:
%  %\begin{nest}
%  %  there is a polynomially-balanced problem in \(\SigmaP k\), namely \(Œ†'\)
%  %  such that
%  %  \begin{nest}
%  %    for every \(X‚àà\Strings\), \(X‚ààŒ†\) if and only if
%  %    \begin{nest}
%  %      there exists a \(Y‚àà\Strings\), in this case \(œµ\), with \((X,œµ)‚ààŒ†'\).
%  %    \end{nest}
%  %  \end{nest}
%  %\end{nest}
%
%  %Since \(Œ†‚àà\SigmaP k\) was arbitrarily chosen, this inclusion holds for all
%  %problems in \(\SigmaP k\).  Thus \(\SigmaP k‚äÜ\SigmaP{k+1}\).
%
%  %The inclusion \(\PiP k‚äÜ\PiP{k+1}\) follows directly, then, from the definition
%  %of \PiP k/\PiP{k+1}.
%  %\[
%  %  \PiP k=\co\SigmaP k‚äÜ\co\SigmaP{k+1}=\PiP{k+1}.  \qedhere
%  %\]
%
%\end{proof}
%
\begin{theorem}{\(\SigmaP k\) and \(\PiP k\) are closed under union, intersection}{ph-closure}

  If \(Œ†‚ÇÅ,Œ†‚ÇÇ‚àà\SigmaP k\), then \(Œ†‚ÇÅ‚à™Œ†‚ÇÇ\) and \(Œ†‚ÇÅ‚à©Œ†‚ÇÇ\) are
  both in \(\SigmaP k\).

  Likewise, if \(Œ†‚ÇÅ,Œ†‚ÇÇ‚àà\PiP k\), then \(Œ†‚ÇÅ‚à™Œ†‚ÇÇ\) and \(Œ†‚ÇÅ‚à©Œ†‚ÇÇ\) are both in \(\PiP
  k\).

\end{theorem}

\begin{proof}

  By induction on \(k\).
  \begin{itemize}

    \item For \(k=0\), let \(Œ†‚ÇÅ,Œ†‚ÇÇ‚àà\SigmaP0=\PiP0=\P\); we wish to show that
      \(Œ†‚ÇÅ‚à™Œ†‚ÇÇ,Œ†‚ÇÅ‚à©Œ†‚ÇÇ‚àà\P\).

      Let \(A‚ÇÅ,A‚ÇÇ\) be polynomial-time algorithms deciding \(Œ†‚ÇÅ,Œ†‚ÇÇ\)
      respectively.  To decide \(Œ†‚ÇÅ‚à™Œ†‚ÇÇ\), run the two algorithms in sequence,
      returning ``yes'' if at least one of the two algorithms returns ``yes'';
      to decide \(Œ†‚ÇÅ‚à©Œ†‚ÇÇ\), run both algorithms and return ``yes'' if both return
      ``yes''.

      \begin{algorithm}{decider for union or intersection of two \P{} problems}{}
        \begin{algorithmic}
          \Given{an arbitrary input string \(X‚àà\Strings\)}
          \State{\(y‚ÇÅ‚ÜêA‚ÇÅ(X)\)}
          \State{\(y‚ÇÇ‚ÜêA‚ÇÇ(X)\)}
          \If{deciding \(Œ†‚ÇÅ‚à™Œ†‚ÇÇ\)}
          \State{\Return ``yes'' if at least one of \(y‚ÇÅ,y‚ÇÇ\) is ``yes'' (i.e., \(y‚ÇÅ‚à®y‚ÇÇ\))}
          \ElsIf{deciding \(Œ†‚ÇÅ‚à©Œ†‚ÇÇ\)}
          \State{\Return ``yes'' if both \(y‚ÇÅ,y‚ÇÇ\) are ``yes'' (i.e., \(y‚ÇÅ‚àßy‚ÇÇ\))}
          \EndIf
        \end{algorithmic}
      \end{algorithm}

      This algorithm runs in polynomial time because both \(A‚ÇÅ\) and \(A‚ÇÇ\) run
      in polynomial time; the overall running time is a sum of two polynomials
      (plus some constants for the last comparison), which is still a
      polynomial.  Thus \(Œ†‚ÇÅ‚à™Œ†‚ÇÇ,Œ†‚ÇÅ‚à©Œ†‚ÇÇ‚àà\P\).

    \item Suppose that the claim holds for all levels below some \(k‚â•1\).
      First, we show that \(\SigmaP k\) is closed under union and intersection.

      Let \(Œ†‚ÇÅ,Œ†‚ÇÇ‚àà\SigmaP k\). Then there exist \(Œ†‚ÇÅ',Œ†‚ÇÇ'‚àà\PiP{k-1}\) and
      polynomials \(p‚ÇÅ,p‚ÇÇ\) such that
      \begin{align*}
        Œ†‚ÇÅ&=\SetBuilder*{X}{‚àÉY\Q\Abs Y‚â§p‚ÇÅ(\Abs X), \quad (X,Y)‚ààŒ†‚ÇÅ'}, \\
        Œ†‚ÇÇ&=\SetBuilder*{X}{‚àÉY\Q\Abs Y‚â§p‚ÇÇ(\Abs X), \quad (X,Y)‚ààŒ†‚ÇÇ'}.
      \end{align*}

      Define two new problems
      \begin{align*}
        Œ†‚ÇÅ''&=\SetBuilder*{(X,(Y‚ÇÅ,Y‚ÇÇ))}{(X,Y‚ÇÅ)‚ààŒ†‚ÇÅ'}, \\
        Œ†‚ÇÇ''&=\SetBuilder*{(X,(Y‚ÇÅ,Y‚ÇÇ))}{(X,Y‚ÇÇ)‚ààŒ†‚ÇÇ'}.
      \end{align*}
      Notice that \(Œ†·µ¢''\) is the same problem as \(Œ†·µ¢'\), differing only in
      that it takes in and ignores an additional component in the input.
      Therefore, they are equivalent; \(Œ†·µ¢'‚àà\PiP{k-1}\) implies
      \(Œ†·µ¢''‚àà\PiP{k-1}\) as well.

      Now, construct the problems
      \begin{align*}
        Œ†_‚à™&=\SetBuilder*{X}{‚àÉ(Y‚ÇÅ,Y‚ÇÇ)\Q(X,(Y‚ÇÅ,Y‚ÇÇ))‚ààŒ†‚ÇÅ''‚à™Œ†‚ÇÇ''}, \\
        Œ†_‚à©&=\SetBuilder*{X}{‚àÉ(Y‚ÇÅ,Y‚ÇÇ)\Q(X,(Y‚ÇÅ,Y‚ÇÇ))‚ààŒ†‚ÇÅ''‚à©Œ†‚ÇÇ''}.
      \end{align*}
      By the induction hypothesis, \(\PiP{k-1}\) is closed under union and
      intersection, so \(Œ†‚ÇÅ''‚à™Œ†‚ÇÇ'',Œ†‚ÇÅ''‚à©Œ†‚ÇÇ''‚àà\PiP{k-1}\).  Additionally, the
      length of the second component \((Y‚ÇÅ,Y‚ÇÇ)\) is bounded by \(p‚ÇÅ+p‚ÇÇ\) (plus
      some constants to account for delimiters), polynomial in the size of the
      ``board'' \(X\).  Thus \(Œ†_‚à™,Œ†_‚à©‚àà\SigmaP k\).

      Finally, we claim that \(Œ†_‚à™=Œ†‚ÇÅ‚à™Œ†‚ÇÇ\), and \(Œ†_‚à©=Œ†‚ÇÅ‚à©Œ†‚ÇÇ\).  We show both
      equalities below.
      \begin{itemize}
        \item Claim: \(Œ†_‚à™=Œ†‚ÇÅ‚à©Œ†‚ÇÇ\).  The following statements are equivalent:
          \begin{itemize}[nosep]
            \item \(X‚ààŒ†_‚à™\).
            \item There exists \((Y‚ÇÅ,Y‚ÇÇ)\) so that \((X,(Y‚ÇÅ,Y‚ÇÇ))\) is in either
              (or both) of \(Œ†‚ÇÅ'',Œ†‚ÇÇ''\).
            \item There exists \(Y‚ÇÅ\) so that \((X,Y‚ÇÅ)‚ààŒ†‚ÇÅ'\), or there exists
              \(Y‚ÇÇ\) so that \((X,Y‚ÇÇ)‚ààŒ†‚ÇÇ'\).
            \item \(X‚ààŒ†‚ÇÅ\) or \(X‚ààŒ†‚ÇÇ\).
            \item \(X‚ààŒ†‚ÇÅ‚à™Œ†‚ÇÇ\).
          \end{itemize}

        \item Claim: \(Œ†_‚à©=Œ†‚ÇÅ‚à©Œ†‚ÇÇ\).  The following are equivalent:
          \begin{itemize}[nosep]
            \item \(X‚ààŒ†_‚à©\).
            \item There exists \((Y‚ÇÅ,Y‚ÇÇ)\) so that \((X,(Y‚ÇÅ,Y‚ÇÇ))\) is in both of
              \(Œ†‚ÇÅ'',Œ†‚ÇÇ''\).
            \item There exists \(Y‚ÇÅ\) so that \((X,Y‚ÇÅ)‚ààŒ†‚ÇÅ'\), and there exists
              \(Y‚ÇÇ\) so that \((X,Y‚ÇÇ)‚ààŒ†‚ÇÇ'\).
            \item \(X‚ààŒ†‚ÇÅ\) and \(X‚ààŒ†‚ÇÇ\).
            \item \(X‚ààŒ†‚ÇÅ‚à©Œ†‚ÇÇ\).
          \end{itemize}

      \end{itemize}

      This concludes the main proof: for any \(Œ†‚ÇÅ,Œ†‚ÇÇ‚àà\SigmaP k\), both
      \(Œ†‚ÇÅ‚à™Œ†‚ÇÇ=Œ†_‚à™\) and \(Œ†‚ÇÅ‚à©Œ†‚ÇÇ=Œ†_‚à©\) are in \(\SigmaP k\), as desired.  Thus
      \(\SigmaP k\) is closed under union and intersection.

      Closure of \(\PiP k\) under union and intersection follows from \(\PiP
      k=\co\SigmaP k\), and from DeMorgan's set identities:
      \[
        \Paren*{Œ†‚ÇÅ‚à™Œ†‚ÇÇ}\Complement=Œ†‚ÇÅ\Complement‚à©Œ†‚ÇÇ\Complement, \qquad
        \Paren*{Œ†‚ÇÅ‚à©Œ†‚ÇÇ}\Complement=Œ†‚ÇÅ\Complement‚à™Œ†‚ÇÇ\Complement.  \qedhere
      \]

  \end{itemize}

\end{proof}

We may now confidently conclude, having proven these two theorems, that
\(\Col[k]‚àà\SigmaP k\).  We discussed why earlier, but just to be thorough, we
restate the full proof below.

\begin{corollary}{}{}

  \(\Col[k]‚àà\SigmaP k\).

\end{corollary}

\begin{proof}

  By induction on \(k\).
  \begin{itemize}
    \item For \(k=0\), \(\Col[0]=\ColProp‚àà\P=\SigmaP0\).
    \item For some \(k‚â•1\), assume \(\Col[k-1]‚àà\SigmaP{k-1}\).  We have
      \[
        \Col[k]
        = \SetBuilder{(Œì,Œ∫,\dotsc)}{\text{\(Œ∫\) is improper}}
        ‚à™ \SetBuilder*{(Œì,Œ∫,\dotsc)}{‚àÉŒ¥\Q(Œì,Œ∫[Œ¥],\dotsc)‚àà\Col[k-1]}.
      \]
      The first set in the union is equivalent to \(\ColProp\Complement\), which
      is in \(\P\) and therefore also in \(\SigmaP k\) (\cref{th:fewer-easier}).
      The second set in the union is by construction a \(\SigmaP k\) problem,
      since \(\Paren*{\Col[k-1]}\Complement‚àà\PiP{k-1}\).  Thus the union of the
      two is also in \SigmaP k (\cref{th:ph-closure}). \qedhere
  \end{itemize}

\end{proof}

Of course, \cref{th:fewer-easier,th:ph-closure} are useful beyond \Col[k]; they
make it much more convenient for us to construct and describe \SigmaP k/\PiP k
problems in general.  One important use-case, as exemplified by \Col[k], is for
incorporating game rules checked at \emph{each turn} of gameplay, rather than
only at the end after all turns have been played.  These rules, for example, can
stipulate conditions on what types of moves are valid, shortcuts to
winning/losing, etc.


%Unsurprisingly, \(\Col[k]‚àà\SigmaP k\).  This inclusion follows straightforwardly
%from the construction of \Col[k] as a \(k\)-turn game; we give a rigorous proof
%below by showing that it complies to the definition of \SigmaP k.
%
%\begin{proof}
%
%  For each \(k=0,1,\dotsc\), define \(\Col[k]'\) to be a modified version of
%  \Col[k] in which the first player automatically wins if the starting coloring
%  is invalid:
%  \[
%    \Col[k]' = \SetBuilderLong{(Œì,Œ∫,(U‚ÇÅ,\dotsc,U‚Çñ))}{
%      \text{\(Œ∫\) is improper, or \(‚àÉŒ¥\colon U‚ÇÅ‚Üí\Colors\Q(Œì,Œ∫[Œ¥],(U‚ÇÇ,\dotsc,U‚Çñ))‚àâ\Col[k-1]'\)}
%    }
%  \]
%
%  When \(k=0\), there are no uncolored vertices, and \(Œ∫\) is a total coloring.
%  Then \(\Col[0]'\) is simply the set of improperly colored graphs, the
%  complement of \ColProp:
%  \[
%    \Col[0]' = \SetBuilder{(Œì,Œ∫)}{\text{\(Œ∫\) is improper}} = \ColProp\Complement.
%  \]
%  Since \(\ColProp‚àà\P\) (\cref{th:3colprop-in-p}), we know that
%  \(\Col[0]'=\ColProp\Complement\) is also in \(\P=\SigmaP0\).
%
%  TODO
%
%\end{proof}
%





%Given a graph \(G\) along with a \(3\)-coloring on \(G\), is the coloring
%proper?  We can solve this problem by simply checking, for each edge, whether
%the two vertices on that edge have different colors.  The run-time of this
%solution is \(\O(e)\) and therefore polynomially-bounded in the size of \(G\).
%Thus the problem of \emph{checking} whether a given \(3\)-coloring is proper is
%in \P.
%
%\subsection{The \(3\)-coloring puzzle}
%
%The puzzle-ification of this problem comes in the following form:
%\begin{definition}[\Problem{3col}]%
%  Given a graph \(G\), is there a way to properly \(3\)-color the vertices of
%  \(G\)?
%  \[
%    \Problem{3col} = \SetBuilder* G {
%      ‚àÉ\,\text{coloring \(C = (c_1,\dotsc,c_n) ‚àà \Set{0,1,2}^n\)} \quad \text{\(C\) is proper}
%    }
%  \]
%\end{definition}
%It is straightforward to see from its definition and the fact that
%properness-checking is in \P{} that \(\Problem{3col} ‚àà \NP\).
%
%The natural question to ask is: is it also \NP-complete?  After all, earlier,
%we could confidently expect that \NP-completeness from \emph{Boolean} \CircSat{}
%because of the universality of Boolean logic, but, at a glance, it isn't
%obvious that graphs and proper colorings are somehow ``fundamental'' to
%computation as Booleans are.  But, in fact, that is exactly the case:
%\begin{theorem}
%  \Problem{3col} is \NP-complete.
%\end{theorem}
%
%\section{Reduction from CSAT}

\section{\texorpdfstring{\Col[k]}{\Problem{3Col}‚Çñ} is \texorpdfstring{\SigmaP k}{ùö∫‚Çñùêè}-complete}

So, we just showed that \(\Col[k]‚àà\SigmaP k\).  But that's hardly surprising.
Given what we understand now about \SigmaP k/\PiP k, almost anything we can
conceive of as a \(k\)-turn game---that is, with polynomial-time-checkable
rules, and \(k\) fixed turns of reasonable size---most likely falls within
\SigmaP k/\PiP k.

Really, the more interesting, more profound result is that \Col[k] is among the
\emph{hardest} \(k\)-turn games: it is \emph{\SigmaP k-complete}.  Before
jumping into the proof of this claim, we first discuss the basic idea behind
it---that graph 3-colorings are ``powerful'' enough to encode boolean circuits.

\subsection{Key idea: using 3-colorings to emulate circuits}

Graph 3-colorings can \emph{emulate} boolean circuits. To illustrate what this
means, associate each boolean value with a color: we take the (convenient)
convention that \ColorId0 means \False{} and \ColorId1 means \True{} (\ColorId2
is an ``auxiliary'' color used to enforce intermediate constraints but never to
represent a boolean value). Then, it is possible to convert any boolean circuit
into a graph so that properness on the graph's colorings causes it to exactly
compute the circuit.

First, we define what it means for a graph to \emph{emulate} boolean functions.

\begin{definition}{boolean 3-coloring graphs}{boolean-graph}

  Let \(Œì\) be a partially pre-colored graph with the following
  specially-labeled vertices:
  \begin{itemize}
    \item There are \(n\) distinct \Term{input vertices}
      \(ùíä‚ÇÅ,\dotsc,ùíä‚Çô‚àà\Vertices(G)\) each joined by an edge to a vertex
      pre-assigned the color \ColorId2.
    \item There exists an \Term{output vertex} \(ùíê‚àà\Vertices(G)\) also joined by
      an edge to a pre-colored \ColorId2.
  \end{itemize}

  Let \(Œ∫\) be an arbitrary proper total coloring of \(Œì\).  For each input or
  output vertex \(v\), since \(v\) neighbors a \ColorId2 by construction and
  \(Œ∫\) is proper, \(Œ∫(v)‚àà\TF\).  We say the \Term{boolean value} assigned by
  \(Œ∫\) to \(v\) is \(\True\) if \(Œ∫(v)=\ColorId1\), and \False{} if
  \(Œ∫(v)=\ColorId0\).

  %Now, let \(Œ∫\colon\Vertices(G)‚Üí\Set{0,1,2}\) be an arbitrary \emph{proper}
  %3-coloring.  Because the three special vertices \(s_\True,s_\False,s_\Aux\)
  %are joined by a triangle, we know that \(Œ∫\) assigns them all three
  %(distinct) available colors.

  %For each input/output vertex \(v\), since \(v\) neighbors \(s_\Aux\) by
  %construction, we know \(Œ∫(v)‚â†Œ∫(s_\Aux)\); then, since there are only three
  %colors, we know \(Œ∫(v)\) must equal \(Œ∫(s_\True)\) or \(Œ∫(s_\False)\).  We
  %say the \Term{boolean value} assigned (by \(Œ∫\)) to each input/output vertex
  %\(v\) is \(\True\) if \(Œ∫(v)=Œ∫(s_\True)\) and \(\False\) if
  %\(Œ∫(v)=Œ∫(s_\False)\).

  To simplify notation, we will conflate the colors \ColorId1/\ColorId0 with
  their corresponding boolean values \True/\False (respectively), except where
  the distinction is needed for clarity.

  Next, let \(œï\colon\TF[n]‚Üí\TF\) be a boolean function.  We say that \(Œì\)
  \Term{emulates} \(œï\) if, for every combination of boolean values
  \((x‚ÇÅ,\dotsc,x‚Çô)\in\TF[n]\), the following hold:
  \begin{itemize}[nosep]
    \item There exists at least one proper 3-coloring \(Œ∫\) such that
      \(Œ∫(ùíä‚±º)=x‚±º\) for each \(j=1,\dotsc,n\).
    \item For every such coloring \(Œ∫\), \(Œ∫(ùíê)=œï(x‚ÇÅ,\dotsc,x‚Çô)\).
  \end{itemize}

  %For example, we may say \(Œ∫(v)=\True\) to really mean
  %\(Œ∫(v)=\ColorId1\), or write \(¬¨Œ∫(v)\) to mean the negation of \emph{the
  %boolean value of} \(v\) (despite \(Œ∫(v)\) being a color).

  %\(Œ∫(v)\) to
  %denote the boolean value of \(v\); i.e., \(Œ∫(v)=\True\)
\end{definition}

%\begin{definition}{boolean graphs as boolean functions}{boolean-graph-functions}%
%
%  Let \(G\) be a boolean graph.  We say that \(G\) computes a well-defined
%  boolean function \(œï\colon\Set{\True,\False}^n‚Üí\Set{\True,\False}\), if, for
%  every combination of boolean values \(x_1,\dotsc,x_n‚àà\Set{\True,\False}^n\),
%  the following hold:
%\end{definition}

%\begin{example}{A graph computing the boolean identity function}{}%
%  The following boolean graph computes the boolean identity function,
%  \(œï(x_1)=x_1\).
%  \begin{center}
%    \begin{tikzpicture}[x=3em, y=3em]
%      \coordinate[vertex](t) at (120:1);
%      \coordinate[vertex](f) at (60:1);
%      \coordinate[vertex](a);
%      \draw (t) -- (f) -- (a) -- (t);
%      \node[vertex label, left] at (t) {\(s_\True\)};
%      \node[vertex label, right] at (f) {\(s_\False\)};
%      \node[vertex label, left] at (a) {\(s_\Aux\)};
%
%      \coordinate[vertex](i) at (-90:1);
%      \node[vertex label, below] at (i.south) {\(i_1=o\)};
%      \draw (i) -- (a);
%    \end{tikzpicture}
%  \end{center}
%
%  TODO is explanation even needed, or is it actually obvious that this works?
%\end{example}

\begin{lemma}{\NOT, \OR, and \AND{} graphs}{boolean-operation-graphs}%
  There exist graphs computing each of the basic boolean operations \NOT, \OR,
  and \AND.
\end{lemma}

\begin{proof}

  \tikzset{
    boolean graph/.style={x=3em, y=3em},
    over/.style={
      preaction={draw=white, line width=3pt},
    },
    triangle/.pic={
      \draw (0,0) -- (0,-1) -- (1,0) -- cycle
      (0,0) coordinate[vertex, fill=ks-true] node[left]{\(s_\True\)}
      (1,0) coordinate[vertex, fill=ks-false] node[right]{\(s_\False\)}
      (0,-1) coordinate[vertex, fill=ks-aux] node[left]{\(s_\Aux\)};
    },
    semi-or graph/.pic={
      \coordinate[vertex](i1);
      \coordinate[vertex](i2) at (0,-1);
      \coordinate[vertex](i1') at (1,0);
      \coordinate[vertex](i2') at (1,-1);
      \coordinate[vertex](t) at (2,0);
      \coordinate[vertex](a) at (0,-1/2);

      \node[vertex label, left] at (i1){\(i_1\)};
      \node[vertex label, left] at (i2){\(i_2\)};
      \node[vertex label, left] at (a){\(s_\Aux\)};
      \node[vertex label, right] at (t){\(s_\True\)};

      \draw (i2') -- (i2) -- (a) -- (i1) -- (i1') -- (t) -- (i2') -- (i1');
    },
    and-or graph/.pic={
      \coordinate[vertex](i1) at (-1,-1);
      \coordinate[vertex](ai) at (0,-3/2);
      \coordinate[vertex](i2) at (-1,-2);

      \coordinate[vertex](i1') at (1,1);
      \coordinate[vertex](i2') at (1,0);

      \coordinate[vertex](i') at (2,1);
      \coordinate[vertex](a') at (2,0);

      \coordinate[vertex](n1) at (1,-1);
      %\coordinate[vertex](an) at (1,-3/2);
      \coordinate[vertex](n2) at (1,-2);

      \coordinate[vertex](no) at (5,1);
      \coordinate[vertex](o) at (6,0);
      \coordinate[vertex](ao) at (6,1);

      \coordinate[vertex](i'') at (3,1);
      \coordinate[vertex](n1') at (2,-1);
      \coordinate[vertex](n2') at (2,-2);

      \coordinate[vertex](no') at (4,1);
      \coordinate[vertex](o1') at (4,-1);
      \coordinate[vertex](o2') at (4,-2);

      \coordinate[vertex](to) at (3,0);
      \coordinate[vertex](ti) at (3,-3/2);

      \node[vertex label, below] at (ai) {\(s_\Aux\)};
      \node[vertex label, below] at (a') {\(s_\Aux\)};

      \node[vertex label, below] at (to) {\(s_\True\)};
      \node[vertex label, below] at (ti) {\(s_\True\)};

      \node[vertex label, above] at (ao) {\(s_\Aux\)};

      \node[vertex label, above] at (i') {\(i'\)};


      \draw
      (i1) -- (ai) -- (i2) (n1) -- (ai) -- (n2)
      (i1) -- (n1) -- (n1') -- (o1') -- (o) (n1') -- (ti) -- (o1')
      (i2) -- (n2) -- (n2') -- (o2') -- (o) (n2') -- (ti) -- (o2')
      %(n1) -- (an) -- (n2)
      (o) -- (no) -- (ao) -- (o)
      (i1) -- (i1') -- (i2') -- (i') -- (i1')
      (a') -- (i') -- (i'') -- (no') -- (no) (no') -- (to) -- (i'');

      \draw[over] (i2) -- (i2');


    },
    or graph/.pic={

      \pic{and-or graph};
      \node[vertex label, left] at (i1) {\(i‚ÇÅ\)};
      \node[vertex label, left] at (i2) {\(i‚ÇÇ\)};
      \node[vertex label, below] at (n1) {\(¬¨i‚ÇÅ\)};
      \node[vertex label, below] at (n2) {\(¬¨i‚ÇÇ\)};
      \node[vertex label, right] at (o) {\(o\)};
      \node[vertex label, above] at (no) {\(¬¨o\)};

    },
    and graph/.pic={

      \pic{and-or graph};
      \node[vertex label, left] at (i1) {\(¬¨i‚ÇÅ\)};
      \node[vertex label, left] at (i2) {\(¬¨i‚ÇÇ\)};
      \node[vertex label, below] at (n1) {\(i‚ÇÅ\)};
      \node[vertex label, below] at (n2) {\(i‚ÇÇ\)};
      \node[vertex label, right] at (o) {\(¬¨o\)};
      \node[vertex label, above] at (no) {\(o\)};

    },
    not graph/.pic={
      \coordinate[vertex](i);
      \coordinate[vertex](o) at (1,0);
      \coordinate[vertex](a) at (0,-1);

      \node[vertex label, left] at (a) {\(s_\Aux\)};
      \node[vertex label, left] at (i) {\(i‚ÇÅ\)};
      \node[vertex label, right] at (o) {\(o\)};
      \draw (i) -- (o) -- (a) -- (i);
    },
  }

  We demonstrate constructions of graphs computing each of the boolean
  operations.

  To improve readability, we adopt the following conventions in the
  illustrations below:
  \begin{itemize}
    \item Assume implicitly the presence of special vertices
      \(s_\True,s_\False,s_\Aux\) joined by a triangle.  We omit them from the
      diagrams, using them only when needed.
    \item To avoid excessive edge crossings, we sometimes illustrate one vertex
      as multiple ``duplicate'' vertices with the same label.
  \end{itemize}

  \begin{description}

  \item[\NOT] The following graph computes the boolean \NOT{} operation:

    \begin{center}
      \begin{tikzpicture}[boolean graph]
        \pic{not graph};
      \end{tikzpicture}
    \end{center}

    Since \(i‚ÇÅ\) neighbors \(o\) (and both neighbor \(s_\Aux\)), they
    necessarily have opposite colors.  Below we show colorings for both
    possible input values (unique up to permutation of colors):

    \[
      \begin{array}{c|c}
        x‚ÇÅ=\True & x‚ÇÅ=\False \\ \midrule
        \begin{tikzpicture}[boolean graph]
          \pic{not graph};
          \coordinate[vertex, fill=ks-true]() at (i);
          \coordinate[vertex, fill=ks-false]() at (o);
          \coordinate[vertex, fill=ks-aux]() at (a);

          \pic at (3,0) {triangle};
        \end{tikzpicture}
        &
        \begin{tikzpicture}[boolean graph]
          \pic{not graph};
          \coordinate[vertex, fill=ks-false]() at (i);
          \coordinate[vertex, fill=ks-true]() at (o);
          \coordinate[vertex, fill=ks-aux]() at (a);

          \pic at (3,0) {triangle};
        \end{tikzpicture}
      \end{array}
    \]

  \item[\OR] Our construction of the boolean \OR{} gate is slightly
    complicated.  To that end, before giving that construction, we first
    introduce a \emph{helper} graph, which we call the ``semi-\OR'' graph.

    \begin{aside}

      \begin{center}
        \begin{tikzpicture}[boolean graph]
          \pic{semi-or graph};
        \end{tikzpicture}
      \end{center}

      Notice that this graph does not yet define a boolean graph, because it has
      no output vertex.  However, it has some useful properties resembling that
      of an \OR-gate.  Examine each of the possible input combinations:
      \begin{itemize}
        \item When \(i_1\) and \(i_2\) are both assigned \True, a proper
          coloring exists:
          \begin{center}
            \begin{tikzpicture}[boolean graph]
              \pic{semi-or graph};
              \coordinate[vertex, fill=ks-true]() at (i1);
              \coordinate[vertex, fill=ks-true]() at (i2);
              \coordinate[vertex, fill=ks-false]() at (i1');
              \coordinate[vertex, fill=ks-aux]() at (i2');
              \coordinate[vertex, fill=ks-aux]() at (a);
              \coordinate[vertex, fill=ks-true]() at (t);

              \pic at (4,0){triangle};
            \end{tikzpicture}
          \end{center}

        \item When \(i_1\) and \(i_2\) are both assigned \False, then no proper
          coloring exists:
          \begin{center}
            \begin{tikzpicture}[boolean graph]
              \pic{semi-or graph};
              \coordinate[vertex, fill=ks-false]() at (i1);
              \coordinate[vertex, fill=ks-false]() at (i2);
              %\coordinate[vertex, fill=ks-false]() at (i1');
              %\coordinate[vertex, fill=ks-aux]() at (i2');
              \coordinate[vertex, fill=ks-aux]() at (a);
              \coordinate[vertex, fill=ks-true]() at (t);
              %\node[above] at (i1') {\(i‚ÇÅ'\)};
              %\node[below] at (i2') {\(i‚ÇÇ'\)};

              \pic at (4,0) {triangle};
            \end{tikzpicture}
          \end{center}

          Each of the two uncolored vertices neighbor \(s_\True\) and an input
          vertex \(i‚ÇÅ\) or \(i‚ÇÇ\), whose color matches \(s_\False\).  Thus the
          uncolored vertices would have to be colored same as \(s_\Aux\).
          However, they neighbor each other as well, forcing them to share a
          color.  Thus there is no proper coloring.

        \item When exactly one of \(i_1,i_2\) is assigned \True{} and the other
          \False, then a proper coloring exists:
          \begin{center}
            \begin{tikzpicture}[boolean graph]
              \pic{semi-or graph};
              \coordinate[vertex, fill=ks-true]() at (i1);
              \coordinate[vertex, fill=ks-false]() at (i2);
              \coordinate[vertex, fill=ks-false]() at (i1');
              \coordinate[vertex, fill=ks-aux]() at (i2');
              \coordinate[vertex, fill=ks-aux]() at (a);
              \coordinate[vertex, fill=ks-true]() at (t);
            \end{tikzpicture}
          \end{center}

    \end{itemize}
    Together, these observations reveal that the semi-\OR{} graph does not
    \emph{compute} the \OR{} operation, but it has the property of being
    \emph{properly-3-colorable} if and only if \(i_1\) or \(i_2\) is assigned
    \True.


  \end{aside}

  Now, we are ready to construct a (``full'') \OR{} graph:

  \begin{center}
    \begin{tikzpicture}[boolean graph]
      \pic{or graph};
    \end{tikzpicture}
  \end{center}

  %\todo[inline]{i made two versions of this graph diagram---the above has less
  %  vertex duplication and is laid out more like a ``gate'', but the below
  %  graph more explicitly/clearly illustrates the parts and may be easier to
  %  explain, at the expense of many more duplicated vertices. @nick, do you
  %find one nicer than the other?}

  \begin{center}
    \begin{tikzpicture}[boolean graph]

      \coordinate[vertex](i1);
      \coordinate[vertex](i2) at (0,-1);
      \coordinate[vertex](a) at (0,-1/2);
      \coordinate[vertex](i') at (2,0);
      \coordinate[vertex](a') at (2,-1/2);
      \coordinate[vertex](no') at (2,-1);
      \coordinate[vertex](no'') at (3,-1);
      \coordinate[vertex](i'') at (3,0);
      \coordinate[vertex](to) at (4,0);

      \coordinate[vertex](in1) at (0,-2);
      \coordinate[vertex](in2) at (0,-4);

      \coordinate[vertex](on) at (0,-6);
      \coordinate[vertex](no) at (1,-6);
      \coordinate[vertex](ao) at (0,-7);


      \foreach \i in {1,2} {
        \coordinate[vertex](i\i') at ($ (i\i) + (1,0) $);
        \node[vertex label, left] at (i\i) {\(i_{\i}\)};
        \node[vertex label, left] at (in\i) {\(i_{\i}\)};

        \coordinate[vertex](n\i) at ($ (in\i) + (1,0) $);
        \coordinate[vertex](a\i) at ($ (in\i) + (0,-1) $);
        \coordinate[vertex](n\i') at ($ (n\i) + (1,0) $);
        \coordinate[vertex](an\i) at ($ (n\i) + (0,-1/2) $);
        \coordinate[vertex](o\i) at ($ (n\i) + (0,-1) $);
        \coordinate[vertex](o\i') at ($ (o\i) + (1,0) $);
        \coordinate[vertex](t\i) at ($ (n\i') + (1,0) $);

        \node[vertex label, above] at (n\i) {\(¬¨i_{\i}\)};
        \node[vertex label, left] at (o\i) {\(o\)};
        \node[vertex label, right] at (an\i) {\(s_\Aux\)};
        \node[vertex label, right] at (t\i) {\(s_\True\)};

        \draw
          (in\i) -- (n\i) -- (a\i) -- (in\i)
          (n\i) -- (an\i) -- (o\i) -- (o\i') -- (n\i') -- (n\i)
          (n\i') -- (t\i) -- (o\i');
      }

      \foreach \v in {a,a1,a2,ao} {
        \node[vertex label, left] at (\v) {\(s_\Aux\)};
      }
      \node[vertex label, right] at (a') {\(s_\Aux\)};

      \node[vertex label, above] at (i') {\(i'\)};
      \node[vertex label, left] at (on) {\(o\)};
      \node[vertex label, left] at (no') {\(¬¨o\)};
      \node[vertex label, right] at (no) {\(¬¨o\)};

      \node[vertex label, right] at (to) {\(s_\True\)};

      \draw
        (i1) -- (a) -- (i2) -- (i2') -- (i1') -- (i1)
        (i1') -- (i') -- (i2')
        (i') -- (a') -- (no') -- (no'') -- (i'') -- (i')
        (i'') -- (to) -- (no'')
        (on) -- (no) -- (ao) -- (on);

    \end{tikzpicture}
  \end{center}

  To see why this construction works,

  %\todo{still not done}




\item[\AND] To construct an \AND{} gate, we apply DeMorgan's law to rewrite
  \AND{} in terms of \NOT{} and \OR:
  \[
    y=x‚ÇÅ‚àßx‚ÇÇ ‚ü∫ ¬¨y=¬¨x‚ÇÅ‚à®¬¨x‚ÇÇ.
  \]

  To that end, we implement an \AND{} graph by negating both the input
  vertices and the output vertex in the \OR{} graph.  We do so by swapping
  vertices
  \[
    i‚ÇÅ‚Üî¬¨i‚ÇÅ, \qquad i‚ÇÇ‚Üî¬¨i‚ÇÇ, \qquad o‚Üî¬¨o
  \]
  in the \OR{} graph construction:

  \begin{center}
    \begin{tikzpicture}[boolean graph]
      \pic{and graph};
    \end{tikzpicture}
  \end{center}


\end{description}

\end{proof}

\begin{theorem}{}{circuit-to-graph}%
  For any boolean circuit \(C\), there exists a boolean graph that computes
  [the function defined by] \(C\).  Moreover, there exists a polynomial-time
  algorithm that performs this conversion from boolean circuits to graphs.
\end{theorem}

\begin{proof}
  We describe an algorithm that, given a circuit \(C\), generates a boolean
  graph computing \(C\).

  First, construct the special triangle \(s_\True,s_\False,s_\Aux\).

  For each wire in \(C\) (including the input and output wires), create a
  corresponding vertex and join it by an edge to \(s_\Aux\). (The color of this
  vertex will correspond to the value carried by the wire.)

  Next, for each [\NOT, \OR, and \AND] gate \(g\) in \(C\), apply
  \cref{lem:boolean-operation-graphs} to construct a subgraph \(Œ≥\) computing
  \(g\).  The input vertices of \(Œ≥\) should exactly correspond to the input
  wires of \(g\), and the output vertex of \(Œ≥\) should correspond to the
  output wire of \(g\).

  %\todo{not done, need some induction to make precise}

\end{proof}

\begin{example}{}{}
  Conversion of an example circuit (e.g., XOR gate?  or something simpler, like
  \(x‚ÇÅ‚àß¬¨x‚ÇÇ\)) to graph.

  TODO
\end{example}

\subsection{Proofs of sigmap completeness of graph coloring games}

%\begin{definition}{The graph 3-colorability problem (\Problem{})}{}
%
%  The \Term{graph 3-colorability problem} is stated as the following yes/no
%  question: given a graph, is it (properly) 3-colorable?
%
%\end{definition}
%
%\begin{theorem}{}{}
%  \Problem{3col} is \NP-complete.
%\end{theorem}

\begin{proof}
  It is straightforward to see that \(\Problem{3col}‚àà\NP\), since it is
  solvable by polynomial-time guess-and-check: guess a color assignment for
  each vertex, then verify that, for each edge \(e\), the two vertices joined
  by \(e\) have distinct colors.  The ``check'' procedure takes
  \(\O(\Abs{\Edges[G]})\) time, which is polynomial with respect to the size of
  the graph.

  To show that \(\Problem{3col}\) is \NP-hard, we show
  \(\CircSat‚â§\Problem{3col}\) by reducing \CircSat{} to \Problem{3col}.
  Specifically, given a circuit \(C\) with inputs \(x‚ÇÅ,\dotsc,x‚Çô\), we wish to
  construct a corresponding graph \(G\) such that \(G\) is 3-colorable if and
  only if \(C\) is satisfiable.

  Let such a circuit \(C\) be given.  Apply the algorithm from
  \cref{th:circuit-to-graph} to produce a graph \(G\) that computes the boolean
  function \(C\), such that the inputs \(x‚ÇÅ,\dotsc,x‚Çô\) of \(C\) correspond
  respectively to input vertices \(i‚ÇÅ,\dotsc,i‚Çô\), and the output of \(C\)
  corresponds to the output vertex \(o\).

  Force the output vertex of \(G\) to take on the boolean value \(\True\) by
  ``merging'' vertices \(o\) and \(s_\True\) into one vertex, keeping all of
  their connections to other vertices.  (Equivalently, if we wish to avoid such
  a ``merging'' operation, we may construct \(G\) assuming \emph{a priori} that
  \(o=s_\True\).  Yet another alternative is to create edges joining \(o\) with
  \(s_\False\) and \(s_\Aux\), thereby forcing it to share a color with
  \(s_\True\).)

  We claim that this resulting graph \(G\) is 3-colorable if and only if \(C\)
  is satisfiable.
  \begin{itemize}
    \item[(\(‚üπ\))] Suppose that \(G\) is 3-colorable.  Then let \(Œ∫\) be a
      proper 3-coloring of \(G\).  Let \(x‚ÇÅ,\dotsc,x‚Çô\) be the respective
      boolean values assigned by \(Œ∫\) to the input vertices \(i‚ÇÅ,\dotsc,i‚Çô\)
      of \(G\). Since \(G\) computes \(C\)
      (\cref{def:boolean-graph-functions}), we know that
      \(Œ∫(o)=C(x‚ÇÅ,\dotsc,x‚Çô)\).  At the same time, we have also ensured by
      construction that \(Œ∫(o)=\True\).  Thus \(x‚ÇÅ,\dotsc,x‚Çô\) is a satisfying
      assignment for \(C\).  Thus \(C\) is satisfiable.

    \item[(\(‚ü∏\))] Suppose that \(C\) is satisfiable.  Then let
      \(x‚ÇÅ,\dotsc,x‚Çô\) be a satisfying assignment for \(C\).  We construct a
      3-coloring for \(G\) as follows:
      \begin{itemize}
        \item Arbitrarily color the special vertices
          \(s_\True,s_\False,s_\Aux\).  Call those colors \(\True,\False,\Aux\)
          respectively.
        \item For each input TODO unfinished
      \end{itemize}


  \end{itemize}


\end{proof}

\section{Can we avoid pre-coloring vertices?}



%\section{Set covering games}
%
%introduce exact set covering problem
%
%introduce set covering game
%
%key idea: embedding circuits in set coverings
%
%proofs of game completeness
